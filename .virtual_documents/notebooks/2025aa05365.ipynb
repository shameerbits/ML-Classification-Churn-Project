#import the required packages.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder


from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_log_error, make_scorer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge





#Data Size : How many total data entries (observations) are present? How many features (variables) are there, including the target column
df = pd.read_csv("../telco_train.csv")
#data_frame.shape retruns the tuple and [0] returns the element of the tuples correspondingly.
print("Rows:", df.shape[0])
print("Columns:", df.shape[1])
df.head()


#Examine the missing values in the dataset size.A cell with no data is called “missing.”
print("Missing values per column:")
print(df.isnull().sum())
#There are no columns with Missing Values as per the recieved output


#Feature Types: What kind of data does each column have?
print("Column types:")
print(df.dtypes)
#Feature Types: More detailed view to know what kind of data does each column have? Data --> Numerical or Categorical
categorical_cols = []
numerical_cols = []
numerical_disguised_as_object = []
id_cols = []

n_rows = len(df)

for col in df.columns:

    # Detect ID-like columns
    if df[col].dtype == 'object' and df[col].nunique() / n_rows > 0.95:
        id_cols.append(col)
        continue

    # Proper numeric columns
    if df[col].dtype in ['int64', 'float64']:
        if df[col].nunique() < 10:
            categorical_cols.append(col)
        else:
            numerical_cols.append(col)

    # Object but numeric
    elif df[col].dtype == 'object':
        converted = pd.to_numeric(df[col], errors='coerce')
        if converted.notna().mean() > 0.9:
            numerical_cols.append(col)
            numerical_disguised_as_object.append(col)
        else:
            categorical_cols.append(col)

    # Other
    else:
        categorical_cols.append(col)

print("ID Columns:", id_cols)
print("Numerical Columns:", numerical_cols)
print("Categorical Columns:", categorical_cols)
print("Numerical but stored as object:", numerical_disguised_as_object)








# Based on Data Analysis,  we found the ID Columns: ['customerID']. Remove Irrelevant Columns
print("Number of Features Before:", df.shape[1])
df.drop(columns=['customerID'], inplace=True)
print("Number of Features After:", df.shape[1])


#Detect Semantic Missing Values. These are the missing values which cannot be detected using df.isnull().sum()
semantic_missing = ["", " ", "NA", "N/A", "null", "None", "unknown", "?"]
df = df.replace(semantic_missing, np.nan)
print("Missing values per column:")
print(df.isnull().sum())


# Based on Data Analysis, Total Charges Column was not detected as Numerical but stored as object: ['TotalCharges'].
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])
print("Column types:")
print(df.dtypes)


#Handle Missing Values Properly. With the detection of Semantic Missing Values mechanism, Total Charges has 11 missing column. Filling the missing value with the median value
df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())
print("Missing values per column:")
print(df.isnull().sum())


#Detect duplicate rows. 
df.duplicated().sum()


#Keeping the duplicated can lead to overfitting, as the model might give "extra weight" to these specific profiles just because they appear more than once
df.drop_duplicates(inplace=True)
df.duplicated().sum()


df.describe()
#Columns with large scales will required standardization.


df.info()





#Target Encoding . Convert target variable Churn.
print("Before Target Encoding : ", df['Churn'].value_counts())
y = df['Churn'].map({'Yes': 1, 'No': 0})
print("After Target Encoding : ",y.value_counts())
#Separate Features & Target
X = df.drop(columns=['Churn'])


categorical_cols = X.select_dtypes(include='object').columns.tolist()
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
print ("Categorical Columns : ", categorical_cols)
print ("Numerical Columns : ", numerical_cols)


#finds columns that are stored as numbers (like 0 and 1) but actually represent categories. If we leave like that, then machine learning models might  try to do "bad math" on it.
for col in numerical_cols:
    if X[col].nunique() == 2:
        X[col] = X[col].astype('object')

X.info()


#Identify Binary Categorical Columns for Label Encoding and Multiclass Categorical Columns for One Hot Encoding.
binary_categorical_cols = []
multiclass_categorical_cols = []
for col in categorical_cols:
    unique_vals = X[col].nunique()    
    if unique_vals == 2:
        binary_categorical_cols.append(col)
    elif unique_vals > 2:
        multiclass_categorical_cols.append(col)
print ("Binary Categorical Columns : ", binary_categorical_cols)
print ("Multiclass Categorical Columns : ", multiclass_categorical_cols)



#Label Encoding
label_encoders = {}
for col in binary_categorical_cols:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col])
    label_encoders[col] = le
print ("Completed Label Encoding for the Binary Categorical Columns.")
#One Hot Encoding
X = pd.get_dummies(X, columns=multiclass_categorical_cols, drop_first=True, dtype=int)
print ("Completed OHE Encoding for the Multiclass Categorical Columns.")










# 1. Feature Engineering: Time Features
df['datetime'] = pd.to_datetime(df['datetime'])
df['hour'] = df['datetime'].dt.hour
df['month'] = df['datetime'].dt.month
df['day'] = df['datetime'].dt.day
df['month_hour'] = df['month'] * df['hour']
df['day_hour'] = df['day'] * df['hour']
df['month_day'] = df['month'] * df['day']

# 2. Input Feature Function:
#One-hot encoding for hour data. # Create 24 hourly columns
hour_dummies = pd.get_dummies(df['hour'], prefix='hour')

# Final features for modeling. # Print the resulting features
X = pd.concat([df, hour_dummies], axis=1)
feature_cols = hour_dummies.columns.tolist()
feature_cols += ['month_hour','month']
print(f"Features for Modeling: {feature_cols}")


# Concatenate with df or X
X = X[feature_cols]
y = df['count']





# Split data into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
# Train Linear Regression
model = LinearRegression()
model.fit(X_train, y_train)
# Predict on validation
y_pred = model.predict(X_val)
# Clamp negative predictions to zero (bike rentals can't be negative)
y_pred = np.maximum(0, y_pred)
# Calculate RMSLE
def rmsle(y_true, y_pred):
    # Ensuring no negative values
    y_pred = np.maximum(0, y_pred)
    y_true = np.maximum(0, y_true)
    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))
rmsle = rmsle(y_val, y_pred)
#rmsle = np.sqrt(mean_squared_log_error(y_val, y_pred))
print(f'Validation RMSLE: {rmsle:.4f}')





#Ridge Regression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_log_error, make_scorer
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import PolynomialFeatures

# Initialize StandardScaler
scaler = StandardScaler()

# Scale the features before applying PolynomialFeatures
X_scaled = scaler.fit_transform(X)

# 2. Expand features polynomially
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly_scaled = poly.fit_transform(X_scaled)

# 3. Train/validation split
X_train_poly_scaled, X_val_poly_scaled, y_train, y_val = train_test_split(X_poly_scaled, y, test_size=0.2, random_state=42)

# 4. Custom RMSLE scorer (clamp negatives to zero before scoring)
def rmsle_clamped(y_true, y_pred):
    # Ensuring no negative values
    y_pred = np.maximum(0, y_pred)
    y_true = np.maximum(0, y_true)
    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))
# def rmsle_clamped(y_true, y_pred):
#     y_pred = np.maximum(0, y_pred)
#     return np.sqrt(mean_squared_log_error(y_true, y_pred))

rmsle_scorer = make_scorer(rmsle_clamped, greater_is_better=False)

# 5. Ridge GridSearchCV with custom scorer
param_grid = {'alpha': [0.01, 0.1, 1, 10, 50, 100]}
ridge_search_scaled = GridSearchCV(Ridge(), param_grid, scoring=rmsle_scorer, cv=5)
ridge_search_scaled.fit(X_train_poly_scaled, y_train)
best_alpha_scaled = ridge_search_scaled.best_params_['alpha']
print("Best Ridge alpha with scaling:", best_alpha_scaled)

# 6. Train best Ridge model and evaluate on validation set
ridge_best_scaled = Ridge(alpha=best_alpha_scaled)
ridge_best_scaled.fit(X_train_poly_scaled, y_train)
y_pred_ridge_scaled = ridge_best_scaled.predict(X_val_poly_scaled)
y_pred_ridge_scaled = np.maximum(0, y_pred_ridge_scaled)

# 7. Calculate RMSLE
rmsle_ridge_scaled = np.sqrt(mean_squared_log_error(y_val, y_pred_ridge_scaled))
print(f'Ridge Validation RMSLE with scaling: {rmsle_ridge_scaled:.4f}')





results = pd.DataFrame({
    'Model': [
        'Linear Regression',
        'Ridge Regression'
    ],
    'RMSLE': [
        rmsle, # From original Linear Regression in Q5
        rmsle_ridge_scaled, # From Ridge in Q6
        
    ]
})

print("Model Performance Summary:")
print(results.to_markdown(index=False))








import matplotlib.pyplot as plt
import seaborn as sns

# Assuming `y_val` and `y_pred_ridge_scaled` are available from previous steps
# If not, ensure the cells calculating these are run first.

# Calculate residuals for the Ridge model
residuals = y_val - y_pred

# Create a residual plot (predicted vs. residuals)
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted Count (Linear)')
plt.ylabel('Residuals (Actual - Predicted)')
plt.title('Residual Plot for Linear Regression')
plt.grid(True)
plt.show()

# Optional: Histogram of residuals to check for normality
plt.figure(figsize=(8, 5))
sns.histplot(residuals, kde=True)
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.title('Histogram of Residuals for Linear Regression')
plt.show()

# Calculate residuals for the Ridge model
residuals = y_val - y_pred_ridge_scaled

# Create a residual plot (predicted vs. residuals)
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted Count (Ridge)')
plt.ylabel('Residuals (Actual - Predicted)')
plt.title('Residual Plot for Ridge Regression (Best Model)')
plt.grid(True)
plt.show()

# Optional: Histogram of residuals to check for normality
plt.figure(figsize=(8, 5))
sns.histplot(residuals, kde=True)
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.title('Histogram of Residuals for Ridge Regression')
plt.show()

















import pandas as pd
import numpy as np

# Read in submission file
submission = pd.read_csv('bike_test.csv')

submission['datetime'] = pd.to_datetime(
    submission['datetime'],
    format='%d-%m-%Y %H:%M',     # <-- main format in your file
    errors='coerce',             # sets problematic rows as NaT, avoids ValueError
    dayfirst=True                # makes sure day comes first
)

if submission['datetime'].isnull().any():
    print("Warning: Some rows contained invalid datetimes and were set to NaT.")

# Extract month and hour features
submission['month'] = submission['datetime'].dt.month
submission['hour'] = submission['datetime'].dt.hour
submission['day'] = submission['datetime'].dt.day

# Reproduce your final feature engineering:
submission['month_hour'] = submission['month'] * submission['hour']
submission['day_hour'] = submission['day'] * submission['hour']
submission['month_day'] = submission['month'] * submission['day']

# One-hot encoding for hour (24 columns), matching train columns
hour_dummies_sub = pd.get_dummies(submission['hour'], prefix='hour')
# Align columns with model's hour_dummies
hour_dummies_sub = hour_dummies_sub.reindex(columns=hour_dummies.columns, fill_value=0)

# Combine all features needed for the model
submission_X = pd.concat([submission, hour_dummies_sub], axis=1)
feature_cols = hour_dummies.columns.tolist() + ['month_hour'] + ['month']
submission_X = submission_X[feature_cols]

# Prediction
submission['count_predicted'] = model.predict(submission_X)
submission['count_predicted'] = np.round(submission['count_predicted']).clip(0).astype(int)

# Final output (only datetime and predicted_count)
submission[['datetime', 'count_predicted']].to_csv('submission.csv', index=False)






